{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuDNN: True\n",
      "GPU available: False\n",
      "Train file: data/SanWen/train.txt\n",
      "Dev file: data/SanWen/valid.txt\n",
      "Test file: data/SanWen/test.txt\n",
      "Char emb: data/vec.txt\n",
      "Bichar emb: None\n",
      "Gaz file: data/sense.txt\n",
      "Data setting loaded from file:  models/SanWen.pkl.dset\n",
      "DATA SUMMARY START:\n",
      "     MAX SENTENCE LENGTH: 86\n",
      "     Number   normalized: True\n",
      "     Use          bigram: False\n",
      "     Word  alphabet size: 4312\n",
      "     Biword alphabet size: 101110\n",
      "     Char  alphabet size: 4313\n",
      "     Gaz   alphabet size: 36593\n",
      "     Label alphabet size: 10\n",
      "     Word embedding size: 100\n",
      "     Biword embedding size: 50\n",
      "     Char embedding size: 30\n",
      "     Gaz embedding size: 200\n",
      "     Norm     word   emb: True\n",
      "     Norm     biword emb: True\n",
      "     Norm     gaz    emb: False\n",
      "     Norm   gaz  dropout: 0.5\n",
      "     Train instance number: 0\n",
      "     Dev   instance number: 0\n",
      "     Test  instance number: 0\n",
      "     Hyperpara  iteration: 100\n",
      "     Hyperpara  batch size: 1\n",
      "     Hyperpara          lr: 0.015\n",
      "     Hyperpara    lr_decay: 0.05\n",
      "     Hyperpara     HP_clip: 5.0\n",
      "     Hyperpara  hidden_dim: 200\n",
      "     Hyperpara     dropout: 0.5\n",
      "     Hyperpara  lstm_layer: 1\n",
      "     Hyperpara      bilstm: False\n",
      "     Hyperpara         GPU: True\n",
      "     Hyperpara     use_gaz: True\n",
      "     Hyperpara fix gaz emb: False\n",
      "     Hyperpara    use_char: False\n",
      "DATA SUMMARY END.\n",
      "Merging data with same (head,tail,sent)...\n",
      "Finish merging\n",
      "Sort data...\n",
      "Finish sorting\n",
      "Total entities: 26766  Entities with multi-sense: 6185  Ratio: 23.107673914667863%\n",
      "Ready for testing.\n",
      "Load model from  models/SanWen.pkl-233\n",
      "build batched bilstm-based encoder...\n",
      "embedding type <class 'torch.nn.modules.sparse.Embedding'>\n",
      "build LatticeLSTM...  forward , Fix emb: False  gaz drop: 0.5\n",
      "load pretrain word emb... (36593, 200)\n",
      "build LatticeLSTM...  backward , Fix emb: False  gaz drop: 0.5\n",
      "load pretrain word emb... (36593, 200)\n",
      "Finish testing\n",
      "Test: time: 802.49s; f1: 0.6714; auc: 0.6050\n"
     ]
    }
   ],
   "source": [
    "!python main.py --status test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuDNN: True\n",
      "GPU available: False\n",
      "Train file: data/FinRE/train.txt\n",
      "Dev file: data/FinRE/valid.txt\n",
      "Test file: data/FinRE/test.txt\n",
      "Char emb: data/vec.txt\n",
      "Bichar emb: None\n",
      "Gaz file: data/sense.txt\n",
      "Data setting loaded from file:  models/FinRE.pkl.dset\n",
      "DATA SUMMARY START:\n",
      "     MAX SENTENCE LENGTH: 86\n",
      "     Number   normalized: True\n",
      "     Use          bigram: False\n",
      "     Word  alphabet size: 3069\n",
      "     Biword alphabet size: 94785\n",
      "     Char  alphabet size: 3068\n",
      "     Gaz   alphabet size: 26430\n",
      "     Label alphabet size: 44\n",
      "     Word embedding size: 100\n",
      "     Biword embedding size: 50\n",
      "     Char embedding size: 30\n",
      "     Gaz embedding size: 200\n",
      "     Norm     word   emb: True\n",
      "     Norm     biword emb: True\n",
      "     Norm     gaz    emb: False\n",
      "     Norm   gaz  dropout: 0.5\n",
      "     Train instance number: 0\n",
      "     Dev   instance number: 0\n",
      "     Test  instance number: 0\n",
      "     Hyperpara  iteration: 100\n",
      "     Hyperpara  batch size: 1\n",
      "     Hyperpara          lr: 0.015\n",
      "     Hyperpara    lr_decay: 0.05\n",
      "     Hyperpara     HP_clip: 5.0\n",
      "     Hyperpara  hidden_dim: 200\n",
      "     Hyperpara     dropout: 0.5\n",
      "     Hyperpara  lstm_layer: 1\n",
      "     Hyperpara      bilstm: False\n",
      "     Hyperpara         GPU: True\n",
      "     Hyperpara     use_gaz: True\n",
      "     Hyperpara fix gaz emb: False\n",
      "     Hyperpara    use_char: False\n",
      "DATA SUMMARY END.\n",
      "Merging data with same (head,tail,sent)...\n",
      "Finish merging\n",
      "Sort data...\n",
      "Finish sorting\n",
      "Total entities: 83235  Entities with multi-sense: 23556  Ratio: 28.300594701748064%\n",
      "Ready for testing.\n",
      "Load model from  models/FinRE.pkl-233\n",
      "build batched bilstm-based encoder...\n",
      "embedding type <class 'torch.nn.modules.sparse.Embedding'>\n",
      "build LatticeLSTM...  forward , Fix emb: False  gaz drop: 0.5\n",
      "load pretrain word emb... (26430, 200)\n",
      "build LatticeLSTM...  backward , Fix emb: False  gaz drop: 0.5\n",
      "load pretrain word emb... (26430, 200)\n",
      "Finish testing\n",
      "Test: time: 1522.51s; f1: 0.5129; auc: 0.3970\n"
     ]
    }
   ],
   "source": [
    "# 测试模型FinRE，修改的是configure.py\n",
    "!python main.py --status test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
